

### GARM Overview

- **Introduction**:  
    GARM (Global Alliance for Responsible Media) unites marketers, agencies, and platforms to reduce harmful content in digital media.
    
- **Purpose**:  
    Develop shared standards for defining harmful content to ensure safe and responsible advertising.
    
- **Key Frameworks**:
    
    - **Content Categories**: Identify and categorize harmful content (e.g., illegal drugs, tobacco, alcohol).
    - **Brand Safety Floor**: Content unsuitable for any advertising.
    - **Brand Suitability Framework**: Guides risk levels for sensitive content.
- **Focus Areas**:
    
    - Stop monetization of harmful content.
    - Ensure clarity and consistency across platforms.
    - Promote responsible marketing while supporting free and safe speech.
- **Impact**:  
    Helps advertisers, agencies, and platforms make informed, ethical decisions to create a safer online ecosystem.

### Speaker Notes:

- **Batch Sizes**: Think of this as the number of examples the model processes before updating its parameters. Smaller batch sizes can be more precise but slower; larger sizes are faster but might miss some nuances.
- **Epochs**: Each epoch represents one full pass through the dataset. Training often requires multiple epochs to ensure the model learns effectively without overfitting.
- **Learning Rates**: This controls how much the model updates during each step. Too high, and it overshoots; too low, and progress is slow. Finding the right balance is critical.
- **Weight Decays**: This adds a penalty for overly complex models, helping to reduce overfitting and improve generalization to unseen data.
# RPC [original 1984 proposed paper](https://dl.acm.org/doi/10.1145/2080.357392)
- function implementation lives on server
- client wants to execute it.
- goal: transparent. looks like executing on own machine

- client: sends msg: marshalled into binary transmitable package.
- [[42e4cce2f4aae747c5e3f34e188484cd_MD5.jpeg|Open: Pasted image 20241020135520.png]]
![[42e4cce2f4aae747c5e3f34e188484cd_MD5.jpeg]]
- [[97e3959828ef355c67e869b7f4648648_MD5.jpeg|Open: Pasted image 20241020135403.png]]
![[97e3959828ef355c67e869b7f4648648_MD5.jpeg]]
- server: unmarshals msg, passes to app, sends fn(x,y) back to client

 Example Javascript RPC
< skip examples 12:00-16:00
```client
let args = {amount: 3.99, currency: 'GBP', /*...*/ }; //f(x,y)
let request = {
	method: 'POST',
	body: JSON.stringify(args),
	headers: {'Content-Type': 'application/json'}
};
fetch('https://example.com/payments', request)
	.then((response) => { //check status
		if (response.ok) success(response.json()); 
		else failure(response.status); // server error
})
.catch((error) => {
	failure(error); // network error
});
```
RPC Benefits
- easy to use, familiar to programmers
- abstracts away network/marshal details in raw network sockets, endianess
## Failures
- client or server crash/reboot
- packet network loss, routing issues
- slow network/server
all look same to client

**Three failure-handling schemas**
- At-Least-Once
	- client gets no ACK, retry fixed # times until give up and ret error
	- **read-only**, otherwise retry misinterpreted by server as multiple requests
	- **idempotent**: or request can only happen once (i.e. create account)
- At-Most-Once
	- server responsible for detecting and rejecting dupe responses
	- transaction ID (XID)
		- client ID (IP) + time of day //prevents parallelism
		- unique ID + seq no // using IP bad unless small network
		- random # (practically doesn't work)
	- issues:
		- seen XIDS grow without bound!!!!
			- soln: on next client request, client specifies upper bound of seqno. "I saw up to seqno N" and server deletes all responses and their XIDs < N 
		- dupe while still executing original?
		- server crash/restart?
			- soln: routinely saves response & XID buffer to disk
			- granularity of backups (1sec, 10sec, etc) based on laboriousness of handling request
```
	if seen[xid]:
		retval = old[xid] // get ret val in buffer of old responses
	else:
		retval = handler()
		old[xid] = retval //cache response in buffer
		seen[xid] = true //mark as seen before

	return retval
```
- Exactly-Once (ideal but hard to implement)
	- client retries if no ACK
	- server filters out seen responses
	- server backups to disk

# MapReduce
- managing lots of big data records (i.e. books, websites) and easily compute some metric over all records
- records all same format (i.e. csv, xml, json, tsv)
	- i.e. html file: teach mapreduce what indicates start/end of each record
	- i.e. csv file: each record its own line
- key:value pair, key not unique. 
- sort all lambs into groups by key, compute summarizing func over all groups/keys
	- key: The  value: count over all words

## Example:
- two records: 
	- mary had a little lamb little lamb little lamb
	- the quick mary jumps over the lazy lamb
- each record: per word occurrence, key-val pair and store on RAM --> disk
	- {'Mary': 1, 'had': 1, 'little': 1, 'lamb': 1, 'little': 1, 'lamb': 1, 'little': 1, 'lamb': 1}
	- {'the': 2, 'quick': 1, 'mary': 1, 'jumps': 1, 'over': 1, 'lazy': 1, 'lamb': 1}
- combine all sets into one without removing dupes
	- {'Mary': 1, 'had': 1, 'little': 1, 'lamb': 1, 'little': 1, 'lamb': 1, 'little': 1, 'lamb': 1, 'the': 2, 'quick': 1, 'mary': 1, 'jumps': 1, 'over': 1, 'lazy': 1, 'lamb': 1}
- partition
	- { 'Mary': [1], 'had': [1], 'little': [1, 1, 1],  'lamb': [1, 1, 1, 1, 1],  'the': [1],  # there are two occurrences of "the" 'quick': [1], 'mary': [1], 'jumps': [1], 'over': [1], 'lazy': [1] }